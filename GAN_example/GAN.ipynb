{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6fd9a2c",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network (GAN) for MNIST Image Generation\n",
    "\n",
    "This notebook demonstrates the implementation of a Generative Adversarial Network (GAN) to generate handwritten digit images similar to the MNIST dataset.\n",
    "\n",
    "## Overview\n",
    "1. **Import Libraries**: Load necessary PyTorch modules and utilities\n",
    "2. **Define Generator**: Create a neural network that generates fake images from random noise\n",
    "3. **Define Discriminator**: Create a neural network that distinguishes real from fake images\n",
    "4. **Data Preparation**: Load and preprocess MNIST dataset (resized to 14x14 for efficiency)\n",
    "5. **Training Loop**: Train both networks adversarially \n",
    "6. **Results Visualization**: Compare generated images with original MNIST images\n",
    "\n",
    "## GAN Architecture\n",
    "- **Generator**: Takes random noise (100 dimensions) → generates 14x14 images\n",
    "- **Discriminator**: Takes 14x14 images → classifies as real (1) or fake (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08614f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c2696",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import essential libraries for GAN implementation:\n",
    "- **PyTorch**: Core deep learning framework\n",
    "- **torchvision**: For MNIST dataset loading and image transformations\n",
    "- **matplotlib**: For visualizing generated vs real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator with fewer layers and smaller output size (14x14)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae4010d",
   "metadata": {},
   "source": [
    "## 2. Define Generator Network\n",
    "\n",
    "The Generator creates fake images from random noise:\n",
    "\n",
    "**Architecture:**\n",
    "- **Input**: 100-dimensional random noise vector (latent space)\n",
    "- **Hidden Layer 1**: 128 neurons with ReLU activation\n",
    "- **Hidden Layer 2**: 256 neurons with ReLU activation  \n",
    "- **Output**: 196 neurons (14×14 pixels) with Tanh activation (outputs in [-1,1] range)\n",
    "\n",
    "The Generator learns to map random noise to realistic-looking digit images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Discriminator with smaller architecture\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c940af9",
   "metadata": {},
   "source": [
    "## 3. Define Discriminator Network\n",
    "\n",
    "The Discriminator classifies images as real or fake:\n",
    "\n",
    "**Architecture:**\n",
    "- **Input**: 196 neurons (flattened 14×14 image)\n",
    "- **Hidden Layer 1**: 256 neurons with LeakyReLU activation (α=0.2)\n",
    "- **Hidden Layer 2**: 128 neurons with LeakyReLU activation  \n",
    "- **Output**: 1 neuron with Sigmoid activation (probability: 0=fake, 1=real)\n",
    "\n",
    "LeakyReLU prevents dying neurons and helps gradient flow during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "img_size = 14 * 14  # Reduced image size (14x14)\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 20  # Fewer epochs for faster training\n",
    "\n",
    "# Prepare the Data with image resizing to 14x14\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(14),  # Resize images to 14x14\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d1665",
   "metadata": {},
   "source": [
    "## 4. Set Hyperparameters and Prepare Data\n",
    "\n",
    "Configure training parameters and load MNIST dataset:\n",
    "\n",
    "**Hyperparameters:**\n",
    "- **Latent Dimension**: 100 (size of noise vector input to Generator)\n",
    "- **Image Size**: 14×14 pixels (reduced from 28×28 for faster training)\n",
    "- **Batch Size**: 64 images per training batch\n",
    "- **Learning Rate**: 0.0002 (typical for GAN training)\n",
    "- **Epochs**: 20 (reduced for demonstration purposes)\n",
    "\n",
    "**Data Preprocessing:**\n",
    "- Resize MNIST images from 28×28 to 14×14\n",
    "- Normalize pixel values to [-1, 1] range (matches Generator's Tanh output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "img_size = 14 * 14  # Reduced image size (14x14)\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 20  # Fewer epochs for faster training\n",
    "\n",
    "# Prepare the Data with image resizing to 14x14\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(14),  # Resize images to 14x14\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models, loss function, and optimizers\n",
    "generator = Generator(input_dim=latent_dim, output_dim=img_size)#.to('cuda')\n",
    "discriminator = Discriminator(input_dim=img_size)#.to('cuda')\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfae2ef",
   "metadata": {},
   "source": [
    "## 5. Initialize Models and Training Components\n",
    "\n",
    "Set up the GAN training framework:\n",
    "\n",
    "**Model Initialization:**\n",
    "- Create Generator and Discriminator instances\n",
    "- Both models can be moved to GPU for faster training (commented out for CPU training)\n",
    "\n",
    "**Training Setup:**\n",
    "- **Loss Function**: Binary Cross Entropy (BCELoss) - standard for binary classification\n",
    "- **Optimizers**: Adam optimizers for both networks with learning rate 0.0002\n",
    "- Adam is preferred over SGD for GAN training due to better convergence properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones((imgs.size(0), 1), requires_grad=False)#.to('cuda')\n",
    "        fake = torch.zeros((imgs.size(0), 1), requires_grad=False)#.to('cuda')\n",
    "        \n",
    "        # Configure input\n",
    "        real_imgs = imgs.view(imgs.size(0), -1)#.to('cuda')\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn((imgs.size(0), latent_dim))#.to('cuda')\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = criterion(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = criterion(discriminator(real_imgs), valid)\n",
    "        fake_loss = criterion(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Print progress\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {i}/{len(train_loader)} \\\n",
    "                  Loss D: {d_loss.item()}, loss G: {g_loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164e99e4",
   "metadata": {},
   "source": [
    "## 6. GAN Training Loop\n",
    "\n",
    "Implement adversarial training where Generator and Discriminator compete:\n",
    "\n",
    "**Training Process (for each batch):**\n",
    "\n",
    "1. **Train Generator:**\n",
    "   - Generate fake images from random noise\n",
    "   - Try to fool Discriminator (maximize D(G(z)))\n",
    "   - Loss: BCE between Discriminator's output on fake images and \"real\" labels\n",
    "\n",
    "2. **Train Discriminator:**\n",
    "   - Train on real images (should output 1)\n",
    "   - Train on fake images (should output 0)  \n",
    "   - Loss: Average of real_loss and fake_loss\n",
    "\n",
    "**Key Points:**\n",
    "- Use `.detach()` when training Discriminator on fake images to prevent Generator updates\n",
    "- Monitor both Generator and Discriminator losses to ensure balanced training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Generated and Original Images\n",
    "def show_images(gen_images, real_images):\n",
    "    gen_images = gen_images.view(gen_images.size(0), 1, 14, 14).cpu().data\n",
    "    real_images = real_images.view(real_images.size(0), 1, 14, 14).cpu().data\n",
    "    \n",
    "    # Concatenate generated and real images\n",
    "    images = torch.cat([gen_images, real_images])\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(images, nrow=8, normalize=True)\n",
    "    \n",
    "    # Set smaller figure size\n",
    "    plt.figure(figsize=(6, 6))  # Smaller figure\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.title('Top Half: Generated Images, Bottom Half: Original Images')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Generate images\n",
    "z = torch.randn(16, latent_dim)#.to('cuda')  # Reduced to 16 for a smaller plot\n",
    "gen_imgs = generator(z)\n",
    "\n",
    "# Get a batch of real images\n",
    "real_imgs, _ = next(iter(train_loader))\n",
    "real_imgs = real_imgs[:16].view(16, -1)#.to('cuda')  # Reduced to 16 for a smaller plot\n",
    "\n",
    "# Show generated vs original images\n",
    "show_images(gen_imgs, real_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd539e83",
   "metadata": {},
   "source": [
    "## 7. Visualize Generated vs Original Images\n",
    "\n",
    "Compare the quality of generated images with real MNIST digits:\n",
    "\n",
    "**Visualization Process:**\n",
    "1. **Generate New Images**: Create 16 fake images from random noise using trained Generator\n",
    "2. **Get Real Images**: Extract 16 real images from the MNIST dataset\n",
    "3. **Create Comparison Grid**: \n",
    "   - Top half: Generated (fake) images\n",
    "   - Bottom half: Original (real) images\n",
    "4. **Display Results**: Show side-by-side comparison to evaluate Generator performance\n",
    "\n",
    "This visualization helps assess how well the GAN has learned to generate realistic handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
