{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b549f1",
   "metadata": {},
   "source": [
    "# Thermal Insulation Optimization using Neural Networks\n",
    "\n",
    "This notebook demonstrates the optimization of thermal insulation design using neural networks as surrogate models. The goal is to minimize heat loss by optimizing the thickness of three insulation layers subject to constraints.\n",
    "\n",
    "## Problem Formulation\n",
    "**Objective**: Minimize heat loss Q = 1/x₁ + 1.5/x₂ + 2.0/x₃\n",
    "\n",
    "**Design Variables:**\n",
    "- x₁: Thickness of insulation layer 1\n",
    "- x₂: Thickness of insulation layer 2  \n",
    "- x₃: Thickness of insulation layer 3\n",
    "\n",
    "**Constraints:**\n",
    "- 5x₁ + 2.5x₂ + x₃ = 1.5 (material budget constraint)\n",
    "- x₁, x₂, x₃ > 0 (physical feasibility)\n",
    "\n",
    "## Approach\n",
    "1. **Generate Training Data**: Create dataset satisfying the constraint equation\n",
    "2. **Train Surrogate Model**: Use neural network to approximate the heat loss function\n",
    "3. **Optimize Design**: Use gradient-based optimization to find minimum heat loss configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Heat loss\n",
    "def heat_loss(x1, x2, x3):\n",
    "    Q = 1 / x1 + 1.5 / x2  + 2.0 / x3\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80ba85",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Define Heat Loss Function\n",
    "\n",
    "Import necessary libraries and define the thermal model:\n",
    "\n",
    "**Heat Loss Function:**\n",
    "```\n",
    "Q = 1/x₁ + 1.5/x₂ + 2.0/x₃\n",
    "```\n",
    "\n",
    "This represents heat transfer through three insulation layers in series, where:\n",
    "- Each term represents thermal resistance of a layer\n",
    "- Coefficients (1, 1.5, 2.0) represent different thermal conductivities\n",
    "- Smaller thickness values lead to higher heat loss (inverse relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9441c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training dataset\n",
    "n_row = 50\n",
    "n_col = 50\n",
    "n_samples = n_row * n_col\n",
    "\n",
    "x1 = torch.zeros(n_samples, 1)\n",
    "x2 = torch.zeros(n_samples, 1)\n",
    "x3 = torch.zeros(n_samples, 1)\n",
    "\n",
    "x1_min, x1_max = 0.05, 0.25\n",
    "\n",
    "for i in range(n_samples):\n",
    "    row = int(i / n_col)\n",
    "    col = i - row * n_col\n",
    "    x1[i] = row * (x1_max - x1_min) / n_row + x1_min\n",
    "    \n",
    "    x2_min = 0.05\n",
    "    x2_max = 0.6 - 2 * x1[i] - 0.05\n",
    "    x2[i] =  col * (x2_max - x2_min) / n_col + x2_min\n",
    "    \n",
    "    x3[i] = 1.5 - 5 * x1[i] - 2.5 * x2[i]\n",
    "\n",
    "x3_min = min(x3)\n",
    "x3_max = max(x3)\n",
    "\n",
    "# Normalize inputs and outputs\n",
    "def normalize(data, data_min, data_max):\n",
    "    return (data - data_min) / (data_max - data_min)\n",
    "\n",
    "def denormalize(data, data_min, data_max):\n",
    "    return data * (data_max - data_min) + data_min\n",
    "\n",
    "# Normalize data\n",
    "x1_norm = normalize(x1, x1_min, x1_max)\n",
    "x2_norm = normalize(x2, x2_min, x2_max)\n",
    "x3_norm = normalize(x3, x3_min, x3_max)\n",
    "Q = heat_loss(x1, x2, x3)\n",
    "Q_min, Q_max = Q.min(), Q.max()  # Save for denormalization\n",
    "Q_norm = normalize(Q, Q_min, Q_max)\n",
    "\n",
    "# Combine normalized inputs into a single tensor\n",
    "inputs_norm = torch.cat((x1_norm, x2_norm), dim=1)\n",
    "outputs_norm = Q_norm.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281baadf",
   "metadata": {},
   "source": [
    "## 2. Generate Training Dataset\n",
    "\n",
    "Create a systematic dataset that satisfies the constraint equation:\n",
    "\n",
    "**Dataset Generation Strategy:**\n",
    "1. **Grid Sampling**: Create 50×50 = 2,500 data points\n",
    "2. **Constraint Satisfaction**: \n",
    "   - Choose x₁ from [0.05, 0.25] (first design variable range)\n",
    "   - For each x₁, determine feasible range for x₂ based on constraint\n",
    "   - Calculate x₃ = 1.5 - 5x₁ - 2.5x₂ (from constraint equation)\n",
    "3. **Data Normalization**: Scale all inputs and outputs to [0,1] range for better neural network training\n",
    "\n",
    "**Constraint Handling:**\n",
    "- Ensures x₂ > 0.05 (minimum thickness)\n",
    "- Ensures x₃ > 0 (feasible solution)\n",
    "- Results in a feasible design space covering all practical configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network model\n",
    "class SurrogateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SurrogateModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 20)\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.fc3 = nn.Linear(20, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38078d",
   "metadata": {},
   "source": [
    "## 3. Define Surrogate Neural Network Model\n",
    "\n",
    "Create a neural network to approximate the heat loss function:\n",
    "\n",
    "**Architecture:**\n",
    "- **Input Layer**: 2 neurons (x₁, x₂) - x₃ is dependent via constraint\n",
    "- **Hidden Layer 1**: 20 neurons with ReLU activation\n",
    "- **Hidden Layer 2**: 20 neurons with ReLU activation  \n",
    "- **Output Layer**: 1 neuron (heat loss Q)\n",
    "\n",
    "**Purpose:**\n",
    "The neural network serves as a differentiable surrogate model for the heat loss function, enabling gradient-based optimization while satisfying constraints implicitly through the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = SurrogateModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 10000\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    predictions = model(inputs_norm)\n",
    "    loss = criterion(predictions, outputs_norm)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_history.append(loss.item())\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24a4f0",
   "metadata": {},
   "source": [
    "## 4. Train the Surrogate Model\n",
    "\n",
    "Train the neural network to learn the relationship between layer thicknesses and heat loss:\n",
    "\n",
    "**Training Configuration:**\n",
    "- **Optimizer**: Adam with learning rate 0.002 (adaptive learning rate for better convergence)\n",
    "- **Loss Function**: Mean Squared Error (MSE) for regression\n",
    "- **Epochs**: 10,000 iterations\n",
    "- **Monitoring**: Print loss every 200 epochs to track training progress\n",
    "\n",
    "**Training Process:**\n",
    "1. Forward pass: Predict heat loss from input thicknesses\n",
    "2. Compute MSE between predictions and actual heat loss values  \n",
    "3. Backpropagate gradients and update network weights\n",
    "4. Track loss history for convergence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07aafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(loss_history, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a4023",
   "metadata": {},
   "source": [
    "## 5. Visualize Training Progress\n",
    "\n",
    "Plot the training loss curve to verify model convergence:\n",
    "\n",
    "**Loss Curve Analysis:**\n",
    "- **Decreasing Trend**: Indicates the model is learning the heat loss function\n",
    "- **Convergence**: Loss should stabilize at a low value\n",
    "- **Overfitting Check**: Smooth decrease without oscillations suggests good training\n",
    "\n",
    "A well-trained surrogate model is essential for reliable optimization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea058f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guess for optimization\n",
    "x_opt = torch.tensor([0.5, 0.5], requires_grad=True)\n",
    "\n",
    "# Optimizer for the optimization process\n",
    "optimizer = optim.Adam([x_opt], lr=0.2)\n",
    "\n",
    "# Optimization loop\n",
    "n_iterations = 4000\n",
    "for iteration in range(n_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Predict normalized Q\n",
    "    Q_pred_norm = model(x_opt)\n",
    "    Q_pred = denormalize(Q_pred_norm, Q_min, Q_max)  # Denormalize for penalty calculation\n",
    "    \n",
    "    # Denormalize inputs\n",
    "    x1_denorm = denormalize(x_opt[0], x1_min, x1_max)\n",
    "    x2_denorm = denormalize(x_opt[1], x2_min, x2_max)\n",
    "    \n",
    "    # Loss for minimization\n",
    "    loss = Q_pred\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (iteration + 1) % 500 == 0:\n",
    "        print(f'Iteration [{iteration + 1}/{n_iterations}], Predicted Q: {Q_pred.item():.4f}, x_opt: {x_opt.data.numpy()}')\n",
    "\n",
    "# Final optimized values (denormalized)\n",
    "x1_opt = denormalize(x_opt[0].detach(), x1_min, x1_max)\n",
    "x2_opt = denormalize(x_opt[1].detach(), x2_min, x2_max)\n",
    "\n",
    "print(f'x1= {x1_opt.item():.2f}')\n",
    "print(f'x2= {x2_opt.item():.2f}')\n",
    "print(f'x3= {1.5 - 5 * x1_opt.item() - 2.5 * x2_opt.item():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ba5ca",
   "metadata": {},
   "source": [
    "## 6. Optimize Thermal Insulation Design\n",
    "\n",
    "Use the trained surrogate model to find the optimal layer thicknesses that minimize heat loss:\n",
    "\n",
    "**Optimization Setup:**\n",
    "- **Initial Guess**: Start with x₁ = x₂ = 0.5 (normalized coordinates)\n",
    "- **Optimizer**: Adam with learning rate 0.2 (higher learning rate for faster convergence)\n",
    "- **Objective**: Minimize predicted heat loss Q\n",
    "- **Iterations**: 4,000 optimization steps\n",
    "\n",
    "**Optimization Process:**\n",
    "1. **Forward Pass**: Use surrogate model to predict heat loss\n",
    "2. **Denormalization**: Convert normalized predictions to physical units for constraint checking\n",
    "3. **Gradient Descent**: Update design variables to minimize heat loss\n",
    "4. **Monitoring**: Track optimization progress every 500 iterations\n",
    "\n",
    "**Final Results:**\n",
    "- Optimal x₁, x₂ values (denormalized to physical units)\n",
    "- Corresponding x₃ calculated from constraint equation\n",
    "- Minimum achievable heat loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a5432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adecea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b1eb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345dffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee6a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fcea5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
